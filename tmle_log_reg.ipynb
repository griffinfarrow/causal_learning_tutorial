{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Machine Learning Tutorial\n",
    "\n",
    "This is a tutorial in using two different causal machine learning approaches: targeted maximum likelihood estimation (TMLE) and double/debiased machine learning (DML). These methods are both going to be used to estimate the treatment effect for a binary treatment.  \n",
    "  \n",
    "This is strongly based on a tutorial given in: https://migariane.github.io/TMLE.nb.html, which implemented TMLE in `R` and https://github.com/matthewvowels1/TargetedLearningTutorial which implemented TMLE on the same problem in `Python`. Here, both are to be implemented in `Python` and we will compare the performance of TMLE and DML.  \n",
    "  \n",
    "See the paper here: *Luque-Fernandez MA, Schomaker M, Rachet B, Schnitzer ME. Targeted maximum likelihood estimation for a binary treatment: A tutorial. Statistics in Medicine. 2018; 37: 2530â€“2546. https://doi.org/10.1002/sim.7628*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf # allows R-like syntax \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import expit \n",
    "\n",
    "from tmle import targeting_step\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tutorial import generate_data, produce_dag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Data Generating Function\n",
    "  \n",
    "Causal ML is about inferring parameters of some data generating function.\n",
    "  \n",
    "A key element is the DAG, we work off the following DAG (taken directly from the paper). This DAG is intended to simulate the causal pathway for mortality from cancer treatment \n",
    "  \n",
    "We then generate date based on that DAG:\n",
    "- `W1` ('sex') and `W2` ('age category') are generated as Bernoulli variables with probabibility 0.5 and 0.65 respectively \n",
    "- `W3` ('cancer stage') and `W4` ('comorbidities') are generated as ordinal variables with 4 and 5 levels respectively. The value for each is generated as a random uniform distribution and the values are rounded off to the closest integer\n",
    "- `A` ('treatment variable') and `Y` ('outcome variable') are generated as binary indicators using a log-linear model. In the treatment and outcome models, there is an interaction term between `W2` and `W4` based on e.g. 'increased risk of comorbidities among older adults' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = produce_dag()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data(2000000, 555) # generate a huge dataset from which we can calculate the 'true' ATE\n",
    "\n",
    "true_EY1 = df['Y1'].mean()\n",
    "true_EY0 = df['Y0'].mean()\n",
    "true_ATE = true_EY1-true_EY0\n",
    "print(f'True ATE = {true_ATE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now generate a much smaller dataset that we will actually use for our methods\n",
    "df = generate_data(10000, 556)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMLE  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Using a binary logistic regression model  \n",
    "  \n",
    "First, we deliberately misspecify the outcome and treatment models (ignoring the interaction term that we know exists)  \n",
    "This is to show that TMLE can still work in this case and reduce bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607563\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9994\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Thu, 21 Nov 2024   Pseudo R-squ.:                 0.08721\n",
      "Time:                        10:30:09   Log-Likelihood:                -6075.6\n",
      "converged:                       True   LL-Null:                       -6656.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                8.525e-249\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.1873      0.070    -16.972      0.000      -1.324      -1.050\n",
      "A              0.8134      0.079     10.286      0.000       0.658       0.968\n",
      "w1            -0.2162      0.044     -4.954      0.000      -0.302      -0.131\n",
      "w2             0.7784      0.046     17.070      0.000       0.689       0.868\n",
      "w3             0.2594      0.019     13.605      0.000       0.222       0.297\n",
      "w4             0.2779      0.016     17.078      0.000       0.246       0.310\n",
      "==============================================================================\n",
      "Initial (biased) ATE estimate = 0.16147770596532363\n"
     ]
    }
   ],
   "source": [
    "# first, we implement an intentionally wrong model (binary logistic regression, without the interaction terms)\n",
    "\n",
    "# this is the outcome model, fit a binary logistic regression for it \n",
    "model = smf.logit(\"Y ~ A + w1 + w2 + w3 + w4\", data=df)\n",
    "model = model.fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# we create a new dataset where the treatment variables are set to 1 and 0 \n",
    "\n",
    "newdata_A1 = df.copy()\n",
    "newdata_A1['A'] = 1\n",
    "\n",
    "newdata_A0 = df.copy()\n",
    "newdata_A0['A'] = 0\n",
    "\n",
    "# predict probabilities based on this data \n",
    "QAW = model.predict(df) # what does our model predict the outcome as (probability)\n",
    "Q1W = model.predict(newdata_A1) # what if the patient had been treated\n",
    "Q0W = model.predict(newdata_A0) # what if the patient had not been treated\n",
    "\n",
    "# initial ATE estimate: \n",
    "init_ATE_est = Q1W.mean() - Q0W.mean() # difference in outcome if every patient treated vs every patient not treated\n",
    "print(f'Initial (biased) ATE estimate = {init_ATE_est}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.335604\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      A   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9995\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 21 Nov 2024   Pseudo R-squ.:                  0.2144\n",
      "Time:                        10:30:09   Log-Likelihood:                -3356.0\n",
      "converged:                       True   LL-Null:                       -4271.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -5.8512      0.143    -40.835      0.000      -6.132      -5.570\n",
      "w1            -0.0393      0.062     -0.634      0.526      -0.161       0.082\n",
      "w2             1.3442      0.077     17.415      0.000       1.193       1.495\n",
      "w3             0.2158      0.027      8.003      0.000       0.163       0.269\n",
      "w4             0.8902      0.027     32.450      0.000       0.836       0.944\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# this is the treatment model (propensity score) \n",
    "ps_model = smf.logit(\"A ~ w1 + w2 + w3 + w4\", data=df)\n",
    "ps_model = ps_model.fit()\n",
    "print(ps_model.summary())\n",
    "\n",
    "# use this model to calculate propensity scores \n",
    "gW = ps_model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9998\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -6074.6\n",
      "Date:                Thu, 21 Nov 2024   Deviance:                       12149.\n",
      "Time:                        10:30:09   Pearson chi2:                 1.00e+04\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):          0.0001960\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "H0W            0.0031      0.019      0.161      0.872      -0.035       0.041\n",
      "H1W            0.0043      0.003      1.353      0.176      -0.002       0.011\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "target_model = targeting_step(df, gW, QAW) # carries out the targeting step to optimise the b-v tradeoff for the ATE\n",
    "epsilon = target_model.params # coefficients in this targeting step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the epsilon values to improve the treatment model\n",
    "\n",
    "# Convert Q0W and Q1W to logit scale and update them\n",
    "logit_Q0W = np.log(Q0W / (1 - Q0W))\n",
    "logit_Q1W = np.log(Q1W / (1 - Q1W))\n",
    "\n",
    "# Update logit values with epsilon adjustments\n",
    "logit_Q0W_1 = logit_Q0W + epsilon['H0W'] / (1 - gW)\n",
    "logit_Q1W_1 = logit_Q1W + epsilon['H1W'] / gW\n",
    "\n",
    "# Convert back to probabilities using inverse-logit\n",
    "Q0W_1 = expit(logit_Q0W_1)\n",
    "Q1W_1 = expit(logit_Q1W_1)\n",
    "\n",
    "# Now we can calculate an improved ATE\n",
    "EY1_tmle_1 = Q1W_1.mean()\n",
    "EY0_tmle_1 = Q0W_1.mean()\n",
    "ATE_tmle_1 = EY1_tmle_1 - EY0_tmle_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Q0W</th>\n",
       "      <th>Q1W</th>\n",
       "      <th>gW</th>\n",
       "      <th>Q0W_1</th>\n",
       "      <th>Q1W_1</th>\n",
       "      <th>Treatment_Effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.380</td>\n",
       "      <td>2.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734167</td>\n",
       "      <td>0.861670</td>\n",
       "      <td>0.202767</td>\n",
       "      <td>0.734931</td>\n",
       "      <td>0.864205</td>\n",
       "      <td>0.129274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.994</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666183</td>\n",
       "      <td>0.818220</td>\n",
       "      <td>0.091842</td>\n",
       "      <td>0.666947</td>\n",
       "      <td>0.825151</td>\n",
       "      <td>0.158204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>4.536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.656060</td>\n",
       "      <td>0.811403</td>\n",
       "      <td>0.377572</td>\n",
       "      <td>0.657192</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.155966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.490919</td>\n",
       "      <td>0.685041</td>\n",
       "      <td>0.060540</td>\n",
       "      <td>0.491750</td>\n",
       "      <td>0.700317</td>\n",
       "      <td>0.208567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>4.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492625</td>\n",
       "      <td>0.686512</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>0.493498</td>\n",
       "      <td>0.695378</td>\n",
       "      <td>0.201881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.777</td>\n",
       "      <td>2.746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693199</td>\n",
       "      <td>0.835962</td>\n",
       "      <td>0.157206</td>\n",
       "      <td>0.693987</td>\n",
       "      <td>0.839717</td>\n",
       "      <td>0.145730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777</td>\n",
       "      <td>4.488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.695004</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>0.696116</td>\n",
       "      <td>0.838581</td>\n",
       "      <td>0.142464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.428</td>\n",
       "      <td>2.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606817</td>\n",
       "      <td>0.776835</td>\n",
       "      <td>0.115846</td>\n",
       "      <td>0.607660</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.175610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.647863</td>\n",
       "      <td>0.805812</td>\n",
       "      <td>0.084869</td>\n",
       "      <td>0.648642</td>\n",
       "      <td>0.813699</td>\n",
       "      <td>0.165057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.601</td>\n",
       "      <td>1.681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563988</td>\n",
       "      <td>0.744735</td>\n",
       "      <td>0.062708</td>\n",
       "      <td>0.564807</td>\n",
       "      <td>0.757683</td>\n",
       "      <td>0.192876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       w1   w2     w3     w4    A    Y   Y1   Y0       Q0W       Q1W  \\\n",
       "0     1.0  1.0  3.380  2.750  0.0  1.0  0.0  1.0  0.734167  0.861670   \n",
       "1     0.0  0.0  3.994  3.031  0.0  1.0  1.0  1.0  0.666183  0.818220   \n",
       "2     1.0  1.0  0.040  4.536  1.0  1.0  1.0  1.0  0.656060  0.811403   \n",
       "3     1.0  0.0  2.001  3.052  0.0  1.0  1.0  1.0  0.490919  0.685041   \n",
       "4     0.0  0.0  0.007  4.160  0.0  1.0  0.0  1.0  0.492625  0.686512   \n",
       "...   ...  ...    ...    ...  ...  ...  ...  ...       ...       ...   \n",
       "9995  0.0  1.0  1.777  2.746  0.0  1.0  1.0  1.0  0.693199  0.835962   \n",
       "9996  1.0  1.0  0.777  4.488  1.0  1.0  1.0  1.0  0.695004  0.837124   \n",
       "9997  1.0  1.0  1.428  2.478  0.0  0.0  1.0  0.0  0.606817  0.776835   \n",
       "9998  0.0  1.0  1.843  1.945  0.0  1.0  0.0  1.0  0.647863  0.805812   \n",
       "9999  1.0  1.0  1.601  1.681  0.0  0.0  0.0  0.0  0.563988  0.744735   \n",
       "\n",
       "            gW     Q0W_1     Q1W_1  Treatment_Effect  \n",
       "0     0.202767  0.734931  0.864205          0.129274  \n",
       "1     0.091842  0.666947  0.825151          0.158204  \n",
       "2     0.377572  0.657192  0.813158          0.155966  \n",
       "3     0.060540  0.491750  0.700317          0.208567  \n",
       "4     0.104653  0.493498  0.695378          0.201881  \n",
       "...        ...       ...       ...               ...  \n",
       "9995  0.157206  0.693987  0.839717          0.145730  \n",
       "9996  0.405263  0.696116  0.838581          0.142464  \n",
       "9997  0.115846  0.607660  0.783270          0.175610  \n",
       "9998  0.084869  0.648642  0.813699          0.165057  \n",
       "9999  0.062708  0.564807  0.757683          0.192876  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all of this info into a new table \n",
    "new_df = pd.DataFrame({\n",
    "    'Q0W': Q0W,\n",
    "    'Q1W': Q1W,\n",
    "    'gW': gW,\n",
    "    'Q0W_1': Q0W_1,\n",
    "    'Q1W_1': Q1W_1,\n",
    "    'Treatment_Effect': Q1W_1 - Q0W_1\n",
    "})\n",
    "\n",
    "# Set the index of the new DataFrame to match the index of the original df (patient id)\n",
    "new_df.index = df.index\n",
    "\n",
    "final_df = df.join(new_df, how='inner') # dataframes are joined on index\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Initial (uncorrected) ATE estimate = 0.16147770596532363\n",
      "Absolute bias (from true value) = 0.0317627940346763\n",
      "Percentage bias (from true value) = 16.43692395469703%\n",
      "==================================================\n",
      "Corrected (by TMLE) ATE estimate = 0.18631804269111385\n",
      "Absolute bias (from true value) = 0.006922457308886076\n",
      "Percentage bias (from true value) = 3.5823014890181297%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# compare ATE estimate (corrected) to naive ATE and true estimate\n",
    "print(\"=\"*50)\n",
    "print(f'Initial (uncorrected) ATE estimate = {init_ATE_est}')\n",
    "print(f'Absolute bias (from true value) = {abs(init_ATE_est-true_ATE)}')\n",
    "print(f'Percentage bias (from true value) = {abs(init_ATE_est-true_ATE)*100/true_ATE}%')\n",
    "print(\"=\"*50)\n",
    "print(f'Corrected (by TMLE) ATE estimate = {ATE_tmle_1}')\n",
    "print(f'Absolute bias (from true value) = {abs(ATE_tmle_1-true_ATE)}')\n",
    "print(f'Percentage bias (from true value) = {abs(ATE_tmle_1-true_ATE)*100/true_ATE}%')\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Using a ML model  \n",
    "  \n",
    "Now we use ML models for the treatment and outcome models, which should be more robust to bias and model misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define predictors and outcome\n",
    "X = df[['A', 'w1', 'w2', 'w3', 'w4']]  # Covariates and treatment\n",
    "y = df['Y']  # Outcome\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gb_model.fit(X, y)\n",
    "\n",
    "QA = gb_model.predict_proba(X)[:,1]\n",
    "Q1 = gb_model.predict_proba(newdata_A1[['A', 'w1', 'w2', 'w3', 'w4']])[:,1]\n",
    "Q0 = gb_model.predict_proba(newdata_A0[['A', 'w1', 'w2', 'w3', 'w4']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16403551801820782\n"
     ]
    }
   ],
   "source": [
    "ml_ATE_est_no_target = Q1.mean() - Q0.mean() # initial estimate of ATE using superlearner, but no targeting\n",
    "print(ml_ATE_est_no_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors and outcome\n",
    "X = df[['w1', 'w2', 'w3', 'w4']]  # Covariates and treatment\n",
    "y = df['A']  # Outcome\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "ps_model_ml = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "ps_model_ml.fit(X, y)\n",
    "\n",
    "propensity_estimates_ml = ps_model_ml.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9998\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -5988.7\n",
      "Date:                Thu, 21 Nov 2024   Deviance:                       11977.\n",
      "Time:                        10:53:21   Pearson chi2:                 9.63e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.001246\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "H0W           -0.0316      0.020     -1.608      0.108      -0.070       0.007\n",
      "H1W            0.0224      0.007      2.996      0.003       0.008       0.037\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "target_model = targeting_step(df, propensity_estimates_ml, QA) # carries out the targeting step to optimise the b-v tradeoff for the ATE\n",
    "epsilon = target_model.params # coefficients in this targeting step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the epsilon values to improve the treatment model\n",
    "\n",
    "# Convert Q0W and Q1W to logit scale and update them\n",
    "logit_Q0 = np.log(Q0 / (1 - Q0))\n",
    "logit_Q1 = np.log(Q1 / (1 - Q1))\n",
    "\n",
    "# Update logit values with epsilon adjustments\n",
    "logit_Q0_1 = logit_Q0 + epsilon['H0W'] / (1 - propensity_estimates_ml)\n",
    "logit_Q1_1 = logit_Q1 + epsilon['H1W'] / propensity_estimates_ml\n",
    "\n",
    "# Convert back to probabilities using inverse-logit\n",
    "Q0_1 = expit(logit_Q0_1)\n",
    "Q1_1 = expit(logit_Q1_1)\n",
    "\n",
    "# Now we can calculate an improved ATE\n",
    "EY1_tmle_2 = Q1_1.mean()\n",
    "EY0_tmle_2 = Q0_1.mean()\n",
    "ATE_tmle_2 = EY1_tmle_2 - EY0_tmle_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Initial (uncorrected) ATE estimate using ML = 0.16403551801820782\n",
      "Absolute bias (from true value) = 0.02920498198179211\n",
      "Percentage bias (from true value) = 15.113282144163424%\n",
      "==================================================\n",
      "Corrected (by TMLE) ATE estimate using ML = 0.20117783691003777\n",
      "Absolute bias (from true value) = 0.00793733691003784\n",
      "Percentage bias (from true value) = 4.107491395456875%\n"
     ]
    }
   ],
   "source": [
    "# compare ATE estimate (corrected) to naive ATE and true estimate\n",
    "print(\"=\"*50)\n",
    "print(f'Initial (uncorrected) ATE estimate using ML = {ml_ATE_est_no_target}')\n",
    "print(f'Absolute bias (from true value) = {abs(ml_ATE_est_no_target-true_ATE)}')\n",
    "print(f'Percentage bias (from true value) = {abs(ml_ATE_est_no_target-true_ATE)*100/true_ATE}%')\n",
    "print(\"=\"*50)\n",
    "print(f'Corrected (by TMLE) ATE estimate using ML = {ATE_tmle_2}')\n",
    "print(f'Absolute bias (from true value) = {abs(ATE_tmle_2-true_ATE)}')\n",
    "print(f'Percentage bias (from true value) = {abs(ATE_tmle_2-true_ATE)*100/true_ATE}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Using stacked classifiers (superlearner)  \n",
    "  \n",
    "This approach uses an ensemble of ML methods, as recommended by the developers of the TMLE `R` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors and outcome\n",
    "X = df[['A', 'w1', 'w2', 'w3', 'w4']]  # Covariates and treatment\n",
    "y = df['Y']  # Outcome\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('gradient_boosting', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(probability=True, kernel='linear', random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X, y)\n",
    "\n",
    "# Predict probabilities\n",
    "QA = stacking_model.predict_proba(X)[:,1]\n",
    "Q1 = stacking_model.predict_proba(newdata_A1[['A', 'w1', 'w2', 'w3', 'w4']])[:,1]\n",
    "Q0 = stacking_model.predict_proba(newdata_A0[['A', 'w1', 'w2', 'w3', 'w4']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10928529809729359\n"
     ]
    }
   ],
   "source": [
    "sl_ATE_est_no_target = Q1.mean() - Q0.mean() # initial estimate of ATE using superlearner, but no targeting\n",
    "print(sl_ATE_est_no_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;gradient_boosting&#x27;,\n",
       "                                GradientBoostingClassifier(random_state=42)),\n",
       "                               (&#x27;random_forest&#x27;,\n",
       "                                RandomForestClassifier(random_state=42)),\n",
       "                               (&#x27;svm&#x27;,\n",
       "                                SVC(kernel=&#x27;linear&#x27;, probability=True,\n",
       "                                    random_state=42))],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;gradient_boosting&#x27;,\n",
       "                                GradientBoostingClassifier(random_state=42)),\n",
       "                               (&#x27;random_forest&#x27;,\n",
       "                                RandomForestClassifier(random_state=42)),\n",
       "                               (&#x27;svm&#x27;,\n",
       "                                SVC(kernel=&#x27;linear&#x27;, probability=True,\n",
       "                                    random_state=42))],\n",
       "                   final_estimator=LogisticRegression())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gradient_boosting</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>random_forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True, random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('gradient_boosting',\n",
       "                                GradientBoostingClassifier(random_state=42)),\n",
       "                               ('random_forest',\n",
       "                                RandomForestClassifier(random_state=42)),\n",
       "                               ('svm',\n",
       "                                SVC(kernel='linear', probability=True,\n",
       "                                    random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define predictors and outcome\n",
    "X = df[['w1', 'w2', 'w3', 'w4']]  # Covariates and treatment\n",
    "y = df['A']  # Outcome\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('gradient_boosting', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(probability=True, kernel='linear', random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_model_ps = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model_ps.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "propensity_estimates_sl = stacking_model_ps.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9998\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -5987.9\n",
      "Date:                Thu, 21 Nov 2024   Deviance:                       11976.\n",
      "Time:                        10:54:12   Pearson chi2:                 9.67e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.001417\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "H0W           -0.0315      0.020     -1.590      0.112      -0.070       0.007\n",
      "H1W            0.0350      0.011      3.321      0.001       0.014       0.056\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "target_model = targeting_step(df, propensity_estimates_sl, QA) # carries out the targeting step to optimise the b-v tradeoff for the ATE\n",
    "epsilon = target_model.params # coefficients in this targeting step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the epsilon values to improve the treatment model\n",
    "\n",
    "# Convert Q0W and Q1W to logit scale and update them\n",
    "logit_Q0 = np.log(Q0 / (1 - Q0))\n",
    "logit_Q1 = np.log(Q1 / (1 - Q1))\n",
    "\n",
    "# Update logit values with epsilon adjustments\n",
    "logit_Q0_1 = logit_Q0 + epsilon['H0W'] / (1 - propensity_estimates_sl)\n",
    "logit_Q1_1 = logit_Q1 + epsilon['H1W'] / propensity_estimates_sl\n",
    "\n",
    "# Convert back to probabilities using inverse-logit\n",
    "Q0_1 = expit(logit_Q0_1)\n",
    "Q1_1 = expit(logit_Q1_1)\n",
    "\n",
    "# Now we can calculate an improved ATE\n",
    "EY1_tmle_3 = Q1_1.mean()\n",
    "EY0_tmle_3 = Q0_1.mean()\n",
    "ATE_tmle_3 = EY1_tmle_3 - EY0_tmle_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Initial (uncorrected) ATE estimate using ML = 0.10928529809729359\n",
      "Absolute bias (from true value) = 0.08395520190270633\n",
      "Percentage bias (from true value) = 43.445965986791784%\n",
      "==================================================\n",
      "Corrected (by TMLE) ATE estimate using ML = 0.19121143105535898\n",
      "Absolute bias (from true value) = 0.002029068944640944\n",
      "Percentage bias (from true value) = 1.0500226115337854%\n"
     ]
    }
   ],
   "source": [
    "# compare ATE estimate (corrected) to naive ATE and true estimate\n",
    "print(\"=\"*50)\n",
    "print(f'Initial (uncorrected) ATE estimate using ML = {sl_ATE_est_no_target}')\n",
    "print(f'Absolute bias (from true value) = {abs(sl_ATE_est_no_target-true_ATE)}')\n",
    "print(f'Percentage bias (from true value) = {abs(sl_ATE_est_no_target-true_ATE)*100/true_ATE}%')\n",
    "print(\"=\"*50)\n",
    "print(f'Corrected (by TMLE) ATE estimate using ML = {ATE_tmle_3}')\n",
    "print(f'Absolute bias (from true value) = {abs(ATE_tmle_3-true_ATE)}')\n",
    "print(f'Percentage bias (from true value) = {abs(ATE_tmle_3-true_ATE)*100/true_ATE}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMLE Summary \n",
    "- Superlearner outperforms the misspecified model or the individual ML model in terms of getting closest to the true ATE value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double ML"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
