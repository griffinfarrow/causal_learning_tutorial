{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMLE Walkthrough\n",
    "This notebook walks through how the targeted maximum likelihood estimation method works for inferring causal parameters from data.  \n",
    "  \n",
    "This is all based on a worked example given in: *Luque-Fernandez MA, Schomaker M, Rachet B, Schnitzer ME. Targeted maximum likelihood estimation for a binary treatment: A tutorial. Statistics in Medicine. 2018; 37: 2530â€“2546. https://doi.org/10.1002/sim.7628*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf # allows R-like syntax \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import expit \n",
    "\n",
    "from tmle import targeting_step\n",
    "from tutorial import generate_data, produce_dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Data Generating Function\n",
    "  \n",
    "Causal ML is about inferring parameters of some data generating function.\n",
    "  \n",
    "A key element is the DAG, we work off the following DAG (taken directly from the paper). This DAG is intended to simulate the causal pathway for mortality from cancer treatment \n",
    "  \n",
    "We then generate date based on that DAG:\n",
    "- `W1` ('sex') and `W2` ('age category') are generated as Bernoulli variables with probabibility 0.5 and 0.65 respectively \n",
    "- `W3` ('cancer stage') and `W4` ('comorbidities') are generated as ordinal variables with 4 and 5 levels respectively. The value for each is generated as a random uniform distribution and the values are rounded off to the closest integer\n",
    "- `A` ('treatment variable') and `Y` ('outcome variable') are generated as binary indicators using a log-linear model. In the treatment and outcome models, there is an interaction term between `W2` and `W4` based on e.g. 'increased risk of comorbidities among older adults' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = produce_dag()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ATE = 0.19324049999999993\n"
     ]
    }
   ],
   "source": [
    "df = generate_data(2000000, 555) # generate a huge dataset from which we can calculate the 'true' ATE\n",
    "\n",
    "true_EY1 = df['Y1'].mean()\n",
    "true_EY0 = df['Y0'].mean()\n",
    "true_ATE = true_EY1-true_EY0\n",
    "print(f'True ATE = {true_ATE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.380</td>\n",
       "      <td>2.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.994</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>4.536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>4.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.777</td>\n",
       "      <td>2.746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777</td>\n",
       "      <td>4.488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.428</td>\n",
       "      <td>2.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.601</td>\n",
       "      <td>1.681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       w1   w2     w3     w4    A    Y   Y1   Y0\n",
       "0     1.0  1.0  3.380  2.750  0.0  1.0  0.0  1.0\n",
       "1     0.0  0.0  3.994  3.031  0.0  1.0  1.0  1.0\n",
       "2     1.0  1.0  0.040  4.536  1.0  1.0  1.0  1.0\n",
       "3     1.0  0.0  2.001  3.052  0.0  1.0  1.0  1.0\n",
       "4     0.0  0.0  0.007  4.160  0.0  1.0  0.0  1.0\n",
       "...   ...  ...    ...    ...  ...  ...  ...  ...\n",
       "9995  0.0  1.0  1.777  2.746  0.0  1.0  1.0  1.0\n",
       "9996  1.0  1.0  0.777  4.488  1.0  1.0  1.0  1.0\n",
       "9997  1.0  1.0  1.428  2.478  0.0  0.0  1.0  0.0\n",
       "9998  0.0  1.0  1.843  1.945  0.0  1.0  0.0  1.0\n",
       "9999  1.0  1.0  1.601  1.681  0.0  0.0  0.0  0.0\n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now generate a much smaller dataset that we will actually use for our methods\n",
    "df = generate_data(10000, 556)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome Model\n",
    "\n",
    "The first step of TMLE is to define an outcome model. This is a model which predicts $E(Y | A, \\vec{W})$, where $Y$ is the outcome variable $A$ is the treatment variable and $\\vec{W}$ is the vector of covariates. We're going to assume that $Y$ and $A$ are binary variables here, but this can be generalised to the continuous case as well  \n",
    "  \n",
    "As stated, the outcome model predicts the expected value of the outcome given the values for the treatment variable and covariates. It can be thought of as:  \n",
    "$$\n",
    "Q(A, \\vec{W}) = E(Y | A, \\vec{W})\n",
    "$$\n",
    "  \n",
    "A big issue with causal inference is specifying the form of this model incorrectly (e.g. assuming that it will be a logistic regression). ML approaches are great for coming up with 'data-adaptive' models that can capture more complicated features in the data.  \n",
    "  \n",
    "That said, in this notebook I'm just going to assume a binary logistic regression model for simplicity. I know this is wrong (because the data generating function has higher order interaction terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607563\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9994\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Thu, 21 Nov 2024   Pseudo R-squ.:                 0.08721\n",
      "Time:                        17:14:18   Log-Likelihood:                -6075.6\n",
      "converged:                       True   LL-Null:                       -6656.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                8.525e-249\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.1873      0.070    -16.972      0.000      -1.324      -1.050\n",
      "A              0.8134      0.079     10.286      0.000       0.658       0.968\n",
      "w1            -0.2162      0.044     -4.954      0.000      -0.302      -0.131\n",
      "w2             0.7784      0.046     17.070      0.000       0.689       0.868\n",
      "w3             0.2594      0.019     13.605      0.000       0.222       0.297\n",
      "w4             0.2779      0.016     17.078      0.000       0.246       0.310\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# this is the outcome model, fit a binary logistic regression for it \n",
    "model = smf.logit(\"Y ~ A + w1 + w2 + w3 + w4\", data=df)\n",
    "model = model.fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use that outcome model to calculate predicted outcomes for three situations:  \n",
    "- what the expected outcomes are from this model in the actual situation of our dataset, using the $A$ and $\\vec{W}$ values for each patient, i.e. $$\\hat{Q}(A, \\vec{W})$$\n",
    "- what the expected outcomes are from this model in a counterfactual where every patient in the population received the treatment i.e. $$\\hat{Q}(1, \\vec{W})$$\n",
    "- what the expected outcomes are from this model in a counterfactual where every patient in the population did not receive the treatment i.e. $$\\hat{Q}(0, \\vec{W})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a new dataset where the treatment variables are set to 1 and 0 \n",
    "\n",
    "newdata_A1 = df.copy()\n",
    "newdata_A1['A'] = 1\n",
    "\n",
    "newdata_A0 = df.copy()\n",
    "newdata_A0['A'] = 0\n",
    "\n",
    "# predict probabilities based on this data \n",
    "QAW = model.predict(df) # what does our model predict the outcome as (probability)\n",
    "Q1W = model.predict(newdata_A1) # what if the patient had been treated\n",
    "Q0W = model.predict(newdata_A0) # what if the patient had not been treated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these predictions to calculate an initial estimate for the average treatment effect based on this outcome model.  \n",
    "  \n",
    "The average treatment effect is:\n",
    "$$\n",
    "\\Psi = \\mathrm{ATE} = E_W\\bigg[E\\big[Y|A=1, \\vec{W}\\big]-E\\big[Y|A=0, \\vec{W}\\big]\\bigg]\n",
    "$$\n",
    "This is the mean difference in outcomes across the population between two counterfactuals: one where every patient received the treatment and one where every patient received the control/did not receive the treatment.  \n",
    "\n",
    "In our case, the G-computation estimate of the ATE is given by:\n",
    "$$\n",
    "\\hat{\\Psi}_{G-comp} = \\frac{1}{N} \\sum_{i=1}^N \\bigg[ \\hat{Q}(1, \\vec{W}_i) - \\hat{Q}(1, \\vec{W}_i) \\bigg]\n",
    "$$\n",
    "where the sum is over the $N$ members of the population and the index $i$ refers to the covariates of person $i$\n",
    "  \n",
    "*N.B. We are using TMLE to calculate the ATE, but it's really just a general estimation process and you can use it to estimate other quantities too, that will change the later targeting step*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial (biased) ATE estimate = 0.16147770596532363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initial ATE estimate: \n",
    "init_ATE_est = Q1W.mean() - Q0W.mean() # difference in outcome if every patient treated vs every patient not treated\n",
    "print(f'Initial (biased) ATE estimate = {init_ATE_est}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment Model\n",
    "  \n",
    "The next stage is to build a model that predicts how likely every patient in the population is to be treated.  \n",
    "  \n",
    "This is also known as the propensity score.  \n",
    "  \n",
    "Using the same notation as above, this model gives:\n",
    "$$\n",
    "g(\\vec{W}) = \\mathrm{Pr}(A=1 | \\vec{W})\n",
    "$$  \n",
    "  \n",
    "Again, this would be best as a ML model! But here we're going to use another binary logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.335604\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      A   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9995\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 21 Nov 2024   Pseudo R-squ.:                  0.2144\n",
      "Time:                        17:14:18   Log-Likelihood:                -3356.0\n",
      "converged:                       True   LL-Null:                       -4271.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -5.8512      0.143    -40.835      0.000      -6.132      -5.570\n",
      "w1            -0.0393      0.062     -0.634      0.526      -0.161       0.082\n",
      "w2             1.3442      0.077     17.415      0.000       1.193       1.495\n",
      "w3             0.2158      0.027      8.003      0.000       0.163       0.269\n",
      "w4             0.8902      0.027     32.450      0.000       0.836       0.944\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# this is the treatment model (propensity score) \n",
    "ps_model = smf.logit(\"A ~ w1 + w2 + w3 + w4\", data=df)\n",
    "ps_model = ps_model.fit()\n",
    "print(ps_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use that model to calculate a propensity score for every patient in our population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use this model to calculate propensity scores \n",
    "gW = ps_model.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the propensity score to calculate three quantities: \n",
    "- The inverse probability of receiving treatment: $$H(1, \\vec{W}) = \\dfrac{1}{g(\\vec{W})}=\\dfrac{1}{\\mathrm{Pr}(A=1|\\vec{W})}$$\n",
    "- The negative inverse probability of receiving treatment: $$H(0, \\vec{W}) = -\\dfrac{1}{1-g(\\vec{W})}=-\\dfrac{1}{\\mathrm{Pr}(A=0|\\vec{W})}$$\n",
    "- The 'clever covariate' which is the the inverse probability of receiving treatment if the subject was treated and the negative inverse probability of receiving treatment if the subject was not treated:\n",
    "$$\n",
    "H(A, \\vec{W}) = \\dfrac{I(A=1)}{\\mathrm{Pr}(A=1|\\vec{W})} - \\dfrac{I(A=0)}{\\mathrm{Pr}(A=0|\\vec{W})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Targeting Step  \n",
    "  \n",
    "There are issues with using ML models to define the above two models; they do not have the correct asymptotic properties for inference. That is to say that they do not converge to some \"true\" value as we add more data, they may just change the model. The models are also designed to optimise the bias-variance tradeoff for the quantity they are calculating, but we actually want to optimise the bias-variance tradeoff for the parameter of interest (that is our estimated value for the ATE).  \n",
    "  \n",
    "The \"magic\" step of TMLE is the \"targeting step\" which uses the treatment model to correct the outcome model to produce an overall model which is aymptotically unbiased for calculating the ATE.  \n",
    "  \n",
    "This step is designed for the ATE and would differ for other quantities.  \n",
    "  \n",
    "The reason we do any of this is \"non-parametric theory\"... complicated, not really sure why it works (but it does because that is how the model was derived)  \n",
    "  \n",
    "The point of the targeting step is to solve an *estimating equation* for the *efficient influence function* (EIF) of our estimand of interest  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No explanation of why this works, but we are going to use this relationship:\n",
    "$$\n",
    "\\mathrm{logit}(E[Y|A, \\vec{W}]) = \\mathrm{logit}(\\hat{E}[Y|A, \\vec{W}]) + \\epsilon H(A, \\vec{W})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially a logistic regression. However, the 'intercept' in our logistic regression $\\mathrm{logit}(\\hat{E}[Y|A, \\vec{W}])$ is not a constant value, but instead a vector of values. We can see it as an 'offset' or 'fixed intercept' in a logistic regression, rather than a constant-value intercept.  \n",
    "  \n",
    "To accomplish the goal of solving an estimating equation for the EIF comes down to fitting a logistic regression with one covariate $H(A,\\vec{W})$ and the initial outcome estimate $\\mathrm{logit}(\\hat{E}[Y|A, \\vec{W}])$ as a fixed intercept. The outcome of the logistic regression is the observed outcome $Y$.  \n",
    "  \n",
    "This gives a value for the parameter $\\epsilon$, which we call a \"fluctuation parameter\" because it provides information about how much to change our initial outcome estimates and $H(A, \\vec{W})$ is the \"clever covariate\" because it cleverly helps solve for the EIF and update estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9998\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -6074.6\n",
      "Date:                Thu, 21 Nov 2024   Deviance:                       12149.\n",
      "Time:                        17:14:18   Pearson chi2:                 1.00e+04\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):          0.0001960\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "H0W            0.0031      0.019      0.161      0.872      -0.035       0.041\n",
      "H1W            0.0043      0.003      1.353      0.176      -0.002       0.011\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "target_model = targeting_step(df, gW, QAW) # carries out the targeting step to optimise the b-v tradeoff for the ATE\n",
    "epsilon = target_model.params # coefficients in this targeting step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have that value for $\\epsilon$, we can update the expected outcomes of all observations:  \n",
    "$$\n",
    "\\hat{E}^*[Y|A, \\vec{W}] = \\mathrm{expit} \\bigg( \\mathrm{logit}(\\hat{E}[Y|A, \\vec{W}]) + \\epsilon H(A, \\vec{W}) \\bigg)\n",
    "$$\n",
    "and the outcomes of the counterfactuals as well  \n",
    "$$\n",
    "\\hat{E}^*[Y|A=1, \\vec{W}] = \\mathrm{expit} \\bigg( \\mathrm{logit}(\\hat{E}[Y|A=1, \\vec{W}]) + \\epsilon H(1, \\vec{W}) \\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{E}^*[Y|A=0, \\vec{W}] = \\mathrm{expit} \\bigg( \\mathrm{logit}(\\hat{E}[Y|A=0, \\vec{W}]) + \\epsilon H(0, \\vec{W}) \\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the epsilon values to improve the treatment model\n",
    "\n",
    "# Convert Q0W and Q1W to logit scale and update them\n",
    "logit_Q0W = np.log(Q0W / (1 - Q0W))\n",
    "logit_Q1W = np.log(Q1W / (1 - Q1W))\n",
    "\n",
    "# Update logit values with epsilon adjustments\n",
    "logit_Q0W_1 = logit_Q0W + epsilon['H0W'] / (1 - gW)\n",
    "logit_Q1W_1 = logit_Q1W + epsilon['H1W'] / gW\n",
    "\n",
    "# Convert back to probabilities using inverse-logit\n",
    "Q0W_1 = expit(logit_Q0W_1)\n",
    "Q1W_1 = expit(logit_Q1W_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means we can finally calculate our TMLE estimate of the ATE:  \n",
    "$$\n",
    "\\hat{\\Psi}_{TMLE} = \\frac{1}{N}\\sum_{i=1}^N \\bigg[ \\hat{E}^*[Y_i|A=1, \\vec{W}_i] - \\hat{E}^*[Y_i|A=0, \\vec{W}_i] \\bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can calculate an improved ATE\n",
    "EY1_tmle_1 = Q1W_1.mean()\n",
    "EY0_tmle_1 = Q0W_1.mean()\n",
    "ATE_tmle_1 = EY1_tmle_1 - EY0_tmle_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Q0W</th>\n",
       "      <th>Q1W</th>\n",
       "      <th>gW</th>\n",
       "      <th>Q0W_1</th>\n",
       "      <th>Q1W_1</th>\n",
       "      <th>Treatment_Effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.380</td>\n",
       "      <td>2.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734167</td>\n",
       "      <td>0.861670</td>\n",
       "      <td>0.202767</td>\n",
       "      <td>0.734931</td>\n",
       "      <td>0.864205</td>\n",
       "      <td>0.129274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.994</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666183</td>\n",
       "      <td>0.818220</td>\n",
       "      <td>0.091842</td>\n",
       "      <td>0.666947</td>\n",
       "      <td>0.825151</td>\n",
       "      <td>0.158204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>4.536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.656060</td>\n",
       "      <td>0.811403</td>\n",
       "      <td>0.377572</td>\n",
       "      <td>0.657192</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.155966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.490919</td>\n",
       "      <td>0.685041</td>\n",
       "      <td>0.060540</td>\n",
       "      <td>0.491750</td>\n",
       "      <td>0.700317</td>\n",
       "      <td>0.208567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>4.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492625</td>\n",
       "      <td>0.686512</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>0.493498</td>\n",
       "      <td>0.695378</td>\n",
       "      <td>0.201881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.777</td>\n",
       "      <td>2.746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693199</td>\n",
       "      <td>0.835962</td>\n",
       "      <td>0.157206</td>\n",
       "      <td>0.693987</td>\n",
       "      <td>0.839717</td>\n",
       "      <td>0.145730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777</td>\n",
       "      <td>4.488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.695004</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>0.696116</td>\n",
       "      <td>0.838581</td>\n",
       "      <td>0.142464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.428</td>\n",
       "      <td>2.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606817</td>\n",
       "      <td>0.776835</td>\n",
       "      <td>0.115846</td>\n",
       "      <td>0.607660</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.175610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.843</td>\n",
       "      <td>1.945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.647863</td>\n",
       "      <td>0.805812</td>\n",
       "      <td>0.084869</td>\n",
       "      <td>0.648642</td>\n",
       "      <td>0.813699</td>\n",
       "      <td>0.165057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.601</td>\n",
       "      <td>1.681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563988</td>\n",
       "      <td>0.744735</td>\n",
       "      <td>0.062708</td>\n",
       "      <td>0.564807</td>\n",
       "      <td>0.757683</td>\n",
       "      <td>0.192876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       w1   w2     w3     w4    A    Y   Y1   Y0       Q0W       Q1W  \\\n",
       "0     1.0  1.0  3.380  2.750  0.0  1.0  0.0  1.0  0.734167  0.861670   \n",
       "1     0.0  0.0  3.994  3.031  0.0  1.0  1.0  1.0  0.666183  0.818220   \n",
       "2     1.0  1.0  0.040  4.536  1.0  1.0  1.0  1.0  0.656060  0.811403   \n",
       "3     1.0  0.0  2.001  3.052  0.0  1.0  1.0  1.0  0.490919  0.685041   \n",
       "4     0.0  0.0  0.007  4.160  0.0  1.0  0.0  1.0  0.492625  0.686512   \n",
       "...   ...  ...    ...    ...  ...  ...  ...  ...       ...       ...   \n",
       "9995  0.0  1.0  1.777  2.746  0.0  1.0  1.0  1.0  0.693199  0.835962   \n",
       "9996  1.0  1.0  0.777  4.488  1.0  1.0  1.0  1.0  0.695004  0.837124   \n",
       "9997  1.0  1.0  1.428  2.478  0.0  0.0  1.0  0.0  0.606817  0.776835   \n",
       "9998  0.0  1.0  1.843  1.945  0.0  1.0  0.0  1.0  0.647863  0.805812   \n",
       "9999  1.0  1.0  1.601  1.681  0.0  0.0  0.0  0.0  0.563988  0.744735   \n",
       "\n",
       "            gW     Q0W_1     Q1W_1  Treatment_Effect  \n",
       "0     0.202767  0.734931  0.864205          0.129274  \n",
       "1     0.091842  0.666947  0.825151          0.158204  \n",
       "2     0.377572  0.657192  0.813158          0.155966  \n",
       "3     0.060540  0.491750  0.700317          0.208567  \n",
       "4     0.104653  0.493498  0.695378          0.201881  \n",
       "...        ...       ...       ...               ...  \n",
       "9995  0.157206  0.693987  0.839717          0.145730  \n",
       "9996  0.405263  0.696116  0.838581          0.142464  \n",
       "9997  0.115846  0.607660  0.783270          0.175610  \n",
       "9998  0.084869  0.648642  0.813699          0.165057  \n",
       "9999  0.062708  0.564807  0.757683          0.192876  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all of this info into a new table \n",
    "new_df = pd.DataFrame({\n",
    "    'Q0W': Q0W,\n",
    "    'Q1W': Q1W,\n",
    "    'gW': gW,\n",
    "    'Q0W_1': Q0W_1,\n",
    "    'Q1W_1': Q1W_1,\n",
    "    'Treatment_Effect': Q1W_1 - Q0W_1\n",
    "})\n",
    "\n",
    "# Set the index of the new DataFrame to match the index of the original df (patient id)\n",
    "new_df.index = df.index\n",
    "\n",
    "final_df = df.join(new_df, how='inner') # dataframes are joined on index\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Initial (uncorrected) ATE estimate = 0.16147770596532363\n",
      "Absolute bias (from true value) = 0.0317627940346763\n",
      "Percentage bias (from true value) = 16.43692395469703%\n",
      "==================================================\n",
      "Corrected (by TMLE) ATE estimate = 0.18631804269111385\n",
      "Absolute bias (from true value) = 0.006922457308886076\n",
      "Percentage bias (from true value) = 3.5823014890181297%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# compare ATE estimate (corrected) to naive ATE and true estimate\n",
    "print(\"=\"*50)\n",
    "print(f'Initial (uncorrected) ATE estimate = {init_ATE_est}')\n",
    "print(f'Absolute bias (from true value) = {abs(init_ATE_est-true_ATE)}')\n",
    "print(f'Percentage bias (from true value) = {abs(init_ATE_est-true_ATE)*100/true_ATE}%')\n",
    "print(\"=\"*50)\n",
    "print(f'Corrected (by TMLE) ATE estimate = {ATE_tmle_1}')\n",
    "print(f'Absolute bias (from true value) = {abs(ATE_tmle_1-true_ATE)}')\n",
    "print(f'Percentage bias (from true value) = {abs(ATE_tmle_1-true_ATE)*100/true_ATE}%')\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can see that even though both the treatment and outcome models are actually specified incorrectly, TMLE still manages to reduce the bias and get us closer to the true ATE value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Calculating standard errors\n",
    "  \n",
    "Once all that is done, we can calculate standard errors. This is another benefit of using the targeting step. To find them, we need to compute the *influence function* (IF) wgucg us essentially a function that defines how much each observation influences the final estimate.  \n",
    "  \n",
    "It is given by: \n",
    "$$\n",
    "\\hat{IF} = \\bigg( Y - \\hat{E}^*(Y|A, \\vec{W})\\bigg) H(A, \\vec{W}) + \\hat{E}^*(Y|A=1,\\vec{W}) - \\hat{E}^*(Y|A=0,\\vec{W}) - \\hat{\\Psi}_{TMLE}\n",
    "$$\n",
    "\n",
    "Once you have it, the standard error of our estimate is given by:\n",
    "$$\n",
    "\\hat{\\sigma} = \\sqrt{\\dfrac{\\mathrm{var}(\\hat{IF})}{N}}\n",
    "$$\n",
    "\n",
    "Note that a TMLE estimator is asymptotically normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = (df['A'] * (df['Y'] - Q1W_1)/gW) + Q1W_1 - EY1_tmle_1\n",
    "d0 = ((1 - df['A']) * (df['Y'] - Q0W_1))/(1 - gW) + Q0W_1 - EY0_tmle_1\n",
    "infl_curve = d1 - d0\n",
    "n = df['Y'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_err_tmle = np.sqrt(np.var(infl_curve)/n)\n",
    "tmle_lower_conf = ATE_tmle_1 - 1.96*std_err_tmle\n",
    "tmle_upper_conf = ATE_tmle_1 + 1.96*std_err_tmle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = 0.18631804269111385 (95% CI: 0.1270185551046911, 0.2456175302775366)\n"
     ]
    }
   ],
   "source": [
    "print(f\"ATE = {ATE_tmle_1} (95% CI: {tmle_lower_conf}, {tmle_upper_conf})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
